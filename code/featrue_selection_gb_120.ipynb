{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab77736-6699-447d-8810-da50a8c891a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eedf17a-17cd-488a-ac47-b315658c2e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_with_gradient_boosting(data: pd.DataFrame,\n",
    "                                             target: str,\n",
    "                                             drop_threshold: float = 0.95,\n",
    "                                             max_iter_mice: int = 12,\n",
    "                                             n_splits: int = 5,\n",
    "                                             random_state: int = 42,\n",
    "                                             gb_params: dict = None):\n",
    "    \"\"\"\n",
    "    Perform feature selection based on Gradient Boosting feature importances.\n",
    "    \n",
    "    Process:\n",
    "        1. Drop rows with missing ratio > drop_threshold.\n",
    "        2. MICE imputation for missing values.\n",
    "        3. Train a Gradient Boosting model using all features to obtain feature importances.\n",
    "        4. Sort features by importance in descending order.\n",
    "        5. For top X% of features (X from 10% to 50% with step=5%), re-train the model\n",
    "           and evaluate performance via cross-validation.\n",
    "        6. Print results for each subset of features.\n",
    "\n",
    "    :param data: Input dataframe (includes features + target column).\n",
    "    :param target: The name of the target column.\n",
    "    :param drop_threshold: If row's missing ratio > drop_threshold, drop it. Default=0.95.\n",
    "    :param max_iter_mice: Number of MICE iteration, default=12.\n",
    "    :param n_splits: Number of folds for cross-validation, default=5.\n",
    "    :param random_state: Seed for reproducibility, default=42.\n",
    "    :param gb_params: A dict of hyperparameters for GradientBoostingClassifier, \n",
    "                      e.g., {\"n_estimators\":300, \"learning_rate\":0.05, \"max_depth\":4}.\n",
    "                      If None, we use a default config.\n",
    "    :return: None (prints out the performance results of different feature subsets).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Drop rows with too many missing values\n",
    "    row_missing_ratio = data.isnull().sum(axis=1) / data.shape[1]\n",
    "    data_cleaned = data.loc[row_missing_ratio <= drop_threshold].copy()\n",
    "    \n",
    "    # 2. Separate target and features\n",
    "    y = data_cleaned[target]\n",
    "    X = data_cleaned.drop(columns=[target])\n",
    "    feature_names = X.columns\n",
    "\n",
    "    # 3. MICE imputation\n",
    "    imputer = IterativeImputer(max_iter=max_iter_mice, random_state=random_state)\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "    # 4. Train a Gradient Boosting model to get feature importances\n",
    "    if gb_params is None:\n",
    "        gb_params = {\n",
    "            \"n_estimators\": 100,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"max_depth\": 3,\n",
    "            \"random_state\": random_state\n",
    "        }\n",
    "    gb_clf = GradientBoostingClassifier(**gb_params)\n",
    "    gb_clf.fit(X_imputed, y)\n",
    "\n",
    "    # Get feature importances and sort\n",
    "    importances = gb_clf.feature_importances_\n",
    "    feat_imp_df = pd.DataFrame({\n",
    "        \"Feature\": feature_names,\n",
    "        \"Importance\": importances\n",
    "    }).sort_values(by=\"Importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # For convenience, get sorted feature names\n",
    "    sorted_features = feat_imp_df[\"Feature\"].tolist()\n",
    "\n",
    "    # 5. For coverage from 10% to 50% in increments of 5%, select top features and re-train\n",
    "    n_total_features = len(feature_names)\n",
    "    coverage_list = range(10, 81, 5)  # 10%, 15%, 20%, ..., 50%\n",
    "\n",
    "    results = []\n",
    "    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    for coverage in coverage_list:\n",
    "        # Compute how many features to keep\n",
    "        n_keep = max(1, int(np.ceil(n_total_features * (coverage / 100.0))))\n",
    "        \n",
    "        # Select top n_keep features\n",
    "        selected_feats = sorted_features[:n_keep]\n",
    "        \n",
    "        # Build a subset of X_imputed with only those features\n",
    "        selected_indices = [feature_names.get_loc(feat) for feat in selected_feats]\n",
    "        X_sub = X_imputed[:, selected_indices]\n",
    "\n",
    "        # Re-train Gradient Boosting on these top features using cross-validation\n",
    "        model = GradientBoostingClassifier(**gb_params)\n",
    "        scores = cross_val_score(model, X_sub, y, cv=cv, scoring=\"accuracy\", n_jobs=-1)\n",
    "        \n",
    "        mean_acc = scores.mean()\n",
    "        std_acc = scores.std()\n",
    "\n",
    "        results.append({\n",
    "            \"Coverage(%)\": coverage,\n",
    "            \"Num_Features\": n_keep,\n",
    "            \"Mean_Accuracy\": mean_acc,\n",
    "            \"Std_Accuracy\": std_acc\n",
    "        })\n",
    "\n",
    "    # 6. Print feature importance + results\n",
    "    print(\"\\n=== Feature Importances (All Features) ===\")\n",
    "    print(feat_imp_df.to_string(index=False))\n",
    "\n",
    "    print(\"\\n=== Feature Selection Results (Top X% of Features) ===\")\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a1a541-d8db-4066-934f-8eda388b4496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to demonstrate feature_selection_with_gradient_boosting usage.\n",
    "    \"\"\"\n",
    "\n",
    "    # Example: read data (please modify the path as necessary)\n",
    "    data = pd.read_csv(r\"../data/final/nicu_120.csv\")\n",
    "\n",
    "    # Suppose your target column name is 'is_infected'\n",
    "    target_column = \"is_infected\"\n",
    "\n",
    "    # Example gradient boosting hyperparameters from prior knowledge or tuning\n",
    "    gb_params = {\n",
    "        \"n_estimators\": 150,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"max_depth\": 4,\n",
    "        \"subsample\": 0.8, \n",
    "        \"random_state\": 42\n",
    "    }\n",
    "\n",
    "    # Call the feature selection function\n",
    "    feature_selection_with_gradient_boosting(\n",
    "        data=data,\n",
    "        target=target_column,\n",
    "        drop_threshold=0.95,\n",
    "        max_iter_mice=12,\n",
    "        n_splits=5,\n",
    "        random_state=42,\n",
    "        gb_params=gb_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d38a975-4fa4-4ed3-a879-b8c6cead0fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Importances (All Features) ===\n",
      "                      Feature  Importance\n",
      "          Lymphocytes_min_120    0.131130\n",
      "                 SaO2_min_120    0.109776\n",
      "          Neutrophils_min_120    0.063108\n",
      "      Temp/Iso/Warmer_min_120    0.062591\n",
      "                SaO2_mean_120    0.058145\n",
      "   BP Cuff [Systolic]_min_120    0.043591\n",
      "          Lymphocytes_max_120    0.038641\n",
      "        Temp Skin [C]_min_120    0.034125\n",
      "            Resp Rate_max_120    0.033755\n",
      "         Lymphocytes_mean_120    0.032397\n",
      "        Temp Skin [C]_max_120    0.027527\n",
      "       Temp Skin [C]_mean_120    0.026703\n",
      "       BP Cuff [Mean]_min_120    0.025174\n",
      "           Glucometer_min_120    0.024658\n",
      "           Glucometer_max_120    0.016230\n",
      "                 SaO2_max_120    0.015273\n",
      "    Temp Axilary [F]_mean_120    0.015119\n",
      "          Heart Rate_mean_120    0.013139\n",
      "      Temp/Iso/Warmer_max_120    0.012327\n",
      "                   SUBJECT_ID    0.012019\n",
      "     Temp Axilary [F]_max_120    0.011335\n",
      "      Red Blood Cells_min_120    0.010417\n",
      "     Temp/Iso/Warmer_mean_120    0.010284\n",
      "          Glucometer_mean_120    0.008421\n",
      "           Heart Rate_max_120    0.008418\n",
      "  BP Cuff [Diastolic]_min_120    0.008267\n",
      "           Heart Rate_min_120    0.008171\n",
      "     Temp Axilary [F]_min_120    0.007881\n",
      "  BP Cuff [Diastolic]_max_120    0.007421\n",
      "       Platelet Count_min_120    0.006537\n",
      "            Resp Rate_min_120    0.006458\n",
      "      Platelet Count_mean_120    0.006394\n",
      "  BP Cuff [Systolic]_mean_120    0.006287\n",
      "       Platelet Count_max_120    0.006081\n",
      "     Red Blood Cells_mean_120    0.005944\n",
      "   BP Cuff [Systolic]_max_120    0.005707\n",
      "    White Blood Cells_min_120    0.005365\n",
      "   White Blood Cells_mean_120    0.004980\n",
      "      BP Cuff [Mean]_mean_120    0.004945\n",
      "       BP Cuff [Mean]_max_120    0.004892\n",
      "                  MCV_min_120    0.004879\n",
      "           Resp Rate_mean_120    0.004781\n",
      "                 MCV_mean_120    0.004546\n",
      "      Red Blood Cells_max_120    0.004297\n",
      "                  RDW_max_120    0.003631\n",
      " BP Cuff [Diastolic]_mean_120    0.002920\n",
      "          Neutrophils_max_120    0.002589\n",
      "    White Blood Cells_max_120    0.002568\n",
      "          Hematocrit_mean_120    0.002260\n",
      "                 RDW_mean_120    0.002077\n",
      "         Neutrophils_mean_120    0.002068\n",
      "                  RDW_min_120    0.001981\n",
      "                  MCV_max_120    0.001906\n",
      "                 MCH_mean_120    0.001498\n",
      "           Hemoglobin_min_120    0.001428\n",
      "                  MCH_max_120    0.001382\n",
      "          Eosinophils_max_120    0.001312\n",
      "                Bands_min_120    0.001292\n",
      "      Metamyelocytes_mean_120    0.001287\n",
      "           Hematocrit_min_120    0.001048\n",
      "               Bands_mean_120    0.001001\n",
      "                 MCHC_min_120    0.000881\n",
      "          Hemoglobin_mean_120    0.000869\n",
      " Atypical Lymphocytes_min_120    0.000699\n",
      "                MCHC_mean_120    0.000689\n",
      "       Metamyelocytes_min_120    0.000674\n",
      "           Hemoglobin_max_120    0.000645\n",
      "       Metamyelocytes_max_120    0.000626\n",
      "            Monocytes_min_120    0.000498\n",
      "                 MCHC_max_120    0.000428\n",
      "           Monocytes_mean_120    0.000380\n",
      "Atypical Lymphocytes_mean_120    0.000371\n",
      "                Bands_max_120    0.000370\n",
      "           Hematocrit_max_120    0.000341\n",
      "            Monocytes_max_120    0.000316\n",
      "            Basophils_min_120    0.000295\n",
      "          Eosinophils_min_120    0.000279\n",
      "           Basophils_mean_120    0.000278\n",
      "           Myelocytes_min_120    0.000206\n",
      " Atypical Lymphocytes_max_120    0.000193\n",
      "                  MCH_min_120    0.000166\n",
      "            Basophils_max_120    0.000160\n",
      "         Eosinophils_mean_120    0.000130\n",
      "          Myelocytes_mean_120    0.000119\n",
      "           Myelocytes_max_120    0.000003\n",
      "\n",
      "=== Feature Selection Results (Top X% of Features) ===\n",
      " Coverage(%)  Num_Features  Mean_Accuracy  Std_Accuracy\n",
      "          10             9       0.789160      0.010870\n",
      "          15            13       0.790538      0.011702\n",
      "          20            17       0.793599      0.011429\n",
      "          25            22       0.795896      0.012841\n",
      "          30            26       0.795130      0.010936\n",
      "          35            30       0.799877      0.011252\n",
      "          40            34       0.799418      0.011982\n",
      "          45            39       0.800030      0.013701\n",
      "          50            43       0.797886      0.010174\n",
      "          55            47       0.802633      0.010828\n",
      "          60            51       0.802939      0.012520\n",
      "          65            56       0.802021      0.010511\n",
      "          70            60       0.803551      0.011420\n",
      "          75            64       0.803093      0.010133\n",
      "          80            68       0.802327      0.010289\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0000cc5-50e4-4f90-8974-d887cbb4c367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
